ci:
  target: gitlab

  broken-tests-packages:
    - gptune
    - superlu-dist    # srun -n 4 hangs
    - papyrus

  broken-specs-url: "s3://spack-binaries/broken-specs"

  pipeline-gen:
  - build-job:
      before_script-:
      - - cat /proc/loadavg || true
        - cat /proc/meminfo | grep 'MemTotal\|MemFree' || true
      - - touch ${SPACK_USER_CACHE_PATH}/cache/*/*  # bump mtime of cache so it is not invalidated
      - - spack env activate --without-view ${SPACK_CONCRETE_ENV_DIR}
        - spack compiler list
        - if [ -n "$SPACK_BUILD_JOBS" ]; then spack config add "config:build_jobs:$SPACK_BUILD_JOBS"; fi
      - - mkdir -p ${SPACK_ARTIFACTS_ROOT}/user_data
        # AWS runners mount E4S public key (verification), UO runners mount public/private (signing/verification)
      - - k=$CI_GPG_KEY_ROOT/e4s.gpg; [[ -r $k ]] && spack gpg trust $k
        # UO runners mount intermediate ci public key (verification), AWS runners mount public/private (signing/verification)
        - k=$CI_GPG_KEY_ROOT/intermediate_ci_signing_key.gpg; [[ -r $k ]] && spack gpg trust $k
        - k=$CI_GPG_KEY_ROOT/spack_public_key.gpg; [[ -r $k ]] && spack gpg trust $k
      script::
      - - spack config blame mirrors
        - spack --color=always --backtrace ci rebuild --tests > >(tee ${SPACK_ARTIFACTS_ROOT}/user_data/pipeline_out.txt) 2> >(tee ${SPACK_ARTIFACTS_ROOT}/user_data/pipeline_err.txt >&2)
      after_script:
      - - cat /proc/loadavg || true
        - cat /proc/meminfo | grep 'MemTotal\|MemFree' || true
      - - time ./bin/spack python ${CI_PROJECT_DIR}/share/spack/gitlab/cloud_pipelines/scripts/common/aggregate_package_logs.spack.py
          --prefix /home/software/spack:${CI_PROJECT_DIR}/opt/spack
          --log install_times.json
          ${SPACK_ARTIFACTS_ROOT}/user_data/install_times.json || true
      variables:
        CI_JOB_SIZE: "default"
        CI_GPG_KEY_ROOT: /mnt/key
        # SPACK_VERBOSE_SCRIPT: "1"
      id_tokens:
        GITLAB_OIDC_TOKEN:
          aud: "${OIDC_TOKEN_AUDIENCE}"

  - signing-job:
      image: { "name": "ghcr.io/spack/notary:latest", "entrypoint": [""] }
      tags: ["aws"]
      script:
      - - aws s3 sync --exclude "*" --include "*spec.json*" ${SPACK_BUILDCACHE_DESTINATION}/build_cache /tmp
        - /sign.sh
        - aws s3 sync --exclude "*" --include "*spec.json.sig*" /tmp ${SPACK_BUILDCACHE_DESTINATION}/build_cache
        - aws s3 cp /tmp/public_keys ${SPACK_BUILDCACHE_DESTINATION}/build_cache/_pgp --recursive --exclude "*" --include "*.pub"
      id_tokens:
        GITLAB_OIDC_TOKEN:
          aud: "${OIDC_TOKEN_AUDIENCE}"

  - copy-job:
      tags: ["service", "x86_64"]
      image: "ghcr.io/spack/python-aws-bash:0.0.1"
      before_script:
      - - if [[ $CI_COMMIT_TAG == "v"* ]]; then export SPACK_REPLACE_VERSION=$(echo "$CI_COMMIT_TAG" | sed 's/\(v[[:digit:]]\+\.[[:digit:]]\+\).*/releases\/\1/'); fi
        - if [[ $CI_COMMIT_TAG == "develop-"* ]]; then export SPACK_REPLACE_VERSION=develop; fi
        - export SPACK_COPY_ONLY_SOURCE=${SPACK_BUILDCACHE_SOURCE//SPACK_REPLACE_VERSION/${SPACK_REPLACE_VERSION}}
      script:
      - - spack env activate --without-view ${SPACK_CONCRETE_ENV_DIR}
        - echo Copying environment specs from ${SPACK_COPY_ONLY_SOURCE} to ${SPACK_COPY_ONLY_DESTINATION}
        - spack buildcache sync "${SPACK_COPY_ONLY_SOURCE}" "${SPACK_COPY_ONLY_DESTINATION}"
        - curl -fLsS https://spack.github.io/keys/spack-public-binary-key.pub -o /tmp/spack-public-binary-key.pub
        - aws s3 cp /tmp/spack-public-binary-key.pub "${SPACK_COPY_ONLY_DESTINATION}/build_cache/_pgp/spack-public-binary-key.pub"
        - spack buildcache update-index --keys "${SPACK_COPY_ONLY_DESTINATION}"
      when: "always"
      retry:
        max: 2
        when:
        - "runner_system_failure"
        - "stuck_or_timeout_failure"
        - "script_failure"
      interruptible: true
      variables:
        CI_JOB_SIZE: "medium"
        KUBERNETES_CPU_REQUEST: "4000m"
        KUBERNETES_MEMORY_REQUEST: "16G"
      id_tokens:
        GITLAB_OIDC_TOKEN:
          aud: "${OIDC_TOKEN_AUDIENCE}"

  - reindex-job:
      tags: ["service", "x86_64"]
      image: "ghcr.io/spack/ubuntu20.04-runner-x86_64:2023-01-01"
      variables:
        CI_JOB_SIZE: "medium"
        KUBERNETES_CPU_REQUEST: "4000m"
        KUBERNETES_MEMORY_REQUEST: "16G"
      id_tokens:
        GITLAB_OIDC_TOKEN:
          aud: "${OIDC_TOKEN_AUDIENCE}"

  # TODO: Remove this block in Spack 0.23
  - cleanup-job:
      tags: ["service"]
      variables:
        CI_JOB_SIZE: "small"
        KUBERNETES_CPU_REQUEST: "500m"
        KUBERNETES_MEMORY_REQUEST: "500M"
      id_tokens:
        GITLAB_OIDC_TOKEN:
          aud: "${OIDC_TOKEN_AUDIENCE}"

  - noop-job:
      tags: ["service"]
      variables:
        CI_JOB_SIZE: "small"
        KUBERNETES_CPU_REQUEST: "500m"
        KUBERNETES_MEMORY_REQUEST: "500M"

  - any-job:
      tags: ["spack"]
      # Linux and Darwin share these, Windows does not
      before_script:
      - - export SPACK_USER_CACHE_PATH="${CI_PROJECT_DIR}/tmp/_user_cache/"
      - - uname -a || true
        - grep -E "vendor|model name" /proc/cpuinfo 2>/dev/null | sort -u || head -n10 /proc/cpuinfo 2>/dev/null || true
        - nproc || true
      - - . "./share/spack/setup-env.sh"
        - spack --version
        - spack arch
      after_script:
      - - cat /proc/loadavg || true

  - match_behavior: first
    submapping:
    - match:
      - hipblas
      - llvm
      - llvm-amdgpu
      - pango
      - paraview
      - py-tensorflow
      - py-torch
      - qt
      - rocblas
      - visit
      build-job:
        tags: [ "huge" ]
        variables:
          CI_JOB_SIZE: huge
          KUBERNETES_CPU_REQUEST: 11000m
          KUBERNETES_MEMORY_REQUEST: 42G

    - match:
      - ascent
      - atk
      - axom
      - cistem
      - cmake
      - ctffind
      - cuda
      - dealii
      - dray
      - dyninst
      - ecp-data-vis-sdk
      - gcc
      - ginkgo
      - hdf5
      - hpx
      - kokkos-kernels
      - kokkos-nvcc-wrapper
      - lbann
      - magma
      - mesa
      - mfem
      - mpich
      - netlib-lapack
      - nvhpc
      - oce
      - openblas
      - openfoam
      - openturns
      - parallelio
      - plumed
      - precice
      #- py-tensorflow
      #- qt
      - raja
      - relion
      #- rocblas
      - rocfft
      - rocsolver
      - rocsparse
      - rust
      - slate
      - strumpack
      - sundials
      - trilinos
      - umpire
      #- visit
      - vtk
      - vtk-h
      - vtk-m
      - warpx
      - wrf
      - wxwidgets
      build-job:
        tags: [ "large" ]
        variables:
          CI_JOB_SIZE: large
          KUBERNETES_CPU_REQUEST: 8000m
          KUBERNETES_MEMORY_REQUEST: 12G

    - match:
      - adios2
      - amrex
      - archer
      - ascent
      - autoconf-archive
      - axom
      - binutils
      - blaspp
      - blt
      - boost
      - butterflypack
      - cabana
      - caliper
      - camp
      - chai
      - conduit
      - curl
      - datatransferkit
      - double-conversion
      - dray
      - eigen
      - faodel
      - ffmpeg
      - fftw
      - fortrilinos
      - gettext
      - gperftools
      - gptune
      - hdf5
      - heffte
      - hpctoolkit
      - hwloc
      - hydrogen
      - hypre
      - kokkos
      - lammps
      - lapackpp
      - legion
      - libtool
      - libxml2
      - libzmq
      - llvm-openmp-ompt
      - mbedtls
      - mfem
      - mpich
      - mvapich2
      - nasm
      - netlib-scalapack
      - omega-h
      - openblas
      - openjpeg
      - openmpi
      - openpmd-api
      - pagmo2
      - papyrus
      - parsec
      - pdt
      - pegtl
      - petsc
      - pumi
      - py-beniget
      - py-cinemasci
      - pygmo
      - py-ipython-genutils
      - py-packaging
      - py-petsc4py
      - py-scipy
      - py-statsmodels
      - py-warlock
      - py-warpx
      - raja
      - samrai
      - slepc
      - slurm
      - sqlite
      - strumpack
      - sundials
      - superlu-dist
      - tasmanian
      - tau
      - upcxx
      - vtk
      - vtk-h
      - vtk-m
      - zfp
      build-job:
        tags: [ "medium" ]
        variables:
          CI_JOB_SIZE: "medium"
          KUBERNETES_CPU_REQUEST: "2000m"
          KUBERNETES_MEMORY_REQUEST: "4G"

    - match:
      - alsa-lib
      - ant
      - antlr
      - argobots
      - autoconf-archive
      - automake
      - berkeley-db
      - bison
      - blt
      - bzip2
      - camp
      - cmake
      - curl
      - czmq
      - darshan-util
      - diffutils
      - docbook-xml
      - exmcutils
      - expat
      - findutils
      - flit
      - freetype
      - gawk
      - gdbm
      - gettext
      - glib
      - gmake
      - gotcha
      - hpcviewer
      - hwloc
      - jansson
      - json-c
      - libbsd
      - libedit
      - libevent
      - libfabric
      - libffi
      - libgcrypt
      - libiconv
      - libidn2
      - libjpeg-turbo
      - libmd
      - libnrm
      - libpciaccess
      - libpng
      - libsigsegv
      - libsodium
      - libunistring
      - libunwind
      - libxml2
      - libyaml
      - libzmq
      - lua
      - lua-luaposix
      - lz4
      - m4
      - meson
      - metis
      - mpfr
      - ncurses
      - ninja
      - numactl
      - openblas
      - openjdk
      - openssh
      - openssl
      - papi
      - parallel-netcdf
      - pcre
      - pcre2
      - pdsh
      - perl
      - perl-data-dumper
      - pkgconf
      - py-alembic
      - py-cffi
      - py-cycler
      - py-decorator
      - py-idna
      - py-jsonschema
      - py-kiwisolver
      - py-mistune
      - py-pycparser
      - py-setuptools
      - py-setuptools-scm
      - py-six
      - py-testpath
      - py-wheel
      - qhull
      - readline
      - sed
      - slurm
      - snappy
      - sqlite
      - superlu
      - swig
      - tar
      - tcl
      - texinfo
      - tut
      - unzip
      - util-linux-uuid
      - util-macros
      - xz
      - yaml-cpp
      - zfp
      - zlib
      - zstd
      build-job:
        tags: [ "small" ]
        variables:
          CI_JOB_SIZE: "small"
          KUBERNETES_CPU_REQUEST: "500m"
          KUBERNETES_MEMORY_REQUEST: "500M"
