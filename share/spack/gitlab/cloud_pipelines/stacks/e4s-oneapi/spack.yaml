spack:
  view: false

  concretizer:
    reuse: false
    unify: false

  packages:
    all:
      require:
      - "target=x86_64_v3"
      prefer:
      - "%oneapi"
      providers:
        blas: [openblas]
        mpi: [mpich]
        tbb: [intel-tbb]
      variants: +mpi
    elfutils:
      variants: ~nls
    gcc-runtime:
      require: "%gcc"
    hdf5:
      require: "%gcc"
      variants: +fortran +hl +shared
    libfabric:
      variants: fabrics=sockets,tcp,udp,rxm
    libunwind:
      variants: +pic +xz
    ncurses:
      variants: +termlib
    openblas:
      variants: threads=openmp
    trilinos:
      variants: +amesos +amesos2 +anasazi +aztec +belos +boost +epetra +epetraext
        +ifpack +ifpack2 +intrepid +intrepid2 +isorropia +kokkos +ml +minitensor +muelu
        +nox +piro +phalanx +rol +rythmos +sacado +stk +shards +shylu +stokhos +stratimikos
        +teko +tempus +tpetra +trilinoscouplings +zoltan +zoltan2 +superlu-dist gotype=long_long
    xz:
      variants: +pic
    mesa:
      version: [21.3.8]
    mpi:
      require: 'mpich@4:'
    mpich:
      require: '~wrapperrpath ~hwloc'
    py-cryptography:
      require: '@38.0.1'
    unzip:
      require: '%gcc'
    binutils:
      require: '%gcc'
      variants: +ld +gold +headers +libiberty ~nls
    llvm:
      require: '%gcc'
    ruby:
      require: '%gcc'
    rust:
      require: '%gcc'
    krb5:
      require: '%gcc'
    papi:
      require: '%gcc'
    openssh:
      require: '%gcc'
    libffi:
      require: "@3.4.4"
    dyninst:
      require: "%gcc"
    bison:
      require: '%gcc'

  specs:
  # CPU
  - adios
  - amrex
  - arborx
  - argobots
  - axom
  - bolt
  - boost
  - butterflypack
  - cabana
  - caliper
  - chai ~benchmarks ~tests
  - charliecloud
  - conduit
  - datatransferkit
  - drishti
  - exaworks
  - flecsi
  - flit
  - flux-core
  - fortrilinos
  - gasnet
  - ginkgo
  - globalarrays
  - gmp
  - gotcha
  - gptune ~mpispawn
  - gromacs
  - h5bench
  - hdf5-vol-async
  - hdf5-vol-cache
  - hdf5-vol-log
  - heffte +fftw
  - hpx networking=mpi
  - hypre
  - kokkos +openmp
  - kokkos-kernels +openmp
  - lammps
  - lbann
  - legion
  - libnrm
  - libpressio +bitgrooming +bzip2 ~cuda ~cusz +fpzip +hdf5 +libdistributed +lua +openmp +python +sz +sz3 +unix +zfp
  - libquo
  - libunwind
  - loki
  - mercury
  - metall
  - mfem
  - mpark-variant
  - mpifileutils ~xattr
  - nccmp
  - nco
  - netlib-scalapack
  - nrm
  - omega-h
  - openmpi
  - papi
  - papyrus
  - parsec ~cuda
  - petsc
  - phist
  - plasma
  - plumed
  - precice
  - pruners-ninja
  - pumi
  - py-h5py
  - py-jupyterhub
  - py-libensemble
  - py-petsc4py
  - py-warpx
  - qthreads scheduler=distrib
  - raja
  - rempi
  - scr
  - slate ~cuda
  - slepc
  - stc
  - strumpack ~slate
  - sundials
  - superlu
  - superlu-dist
  - sz3
  - tasmanian
  - trilinos +amesos +amesos2 +anasazi +aztec +belos +boost +epetra +epetraext +ifpack +ifpack2 +intrepid +intrepid2 +isorropia +kokkos +ml +minitensor +muelu +nox +piro +phalanx +rol +rythmos +sacado +stk +shards +shylu +stokhos +stratimikos +teko +tempus +tpetra +trilinoscouplings +zoltan +zoltan2 +superlu-dist gotype=long_long
  - turbine
  - umap
  - umpire
  - variorum
  - wannier90
  - xyce +mpi +shared +pymi +pymi_static_tpls
  # INCLUDED IN ECP DAV CPU
  - adios2                # mgard:  mgard.tpp:63:48: error: non-constant-expression cannot be narrowed from type 'int' to 'unsigned long' in initializer list [-Wc++11-narrowing]
  - ascent
  - darshan-runtime
  - darshan-util
  - faodel
  - hdf5
  - libcatalyst
  - parallel-netcdf
  # - paraview            # paraview: VTK/ThirdParty/cgns/vtkcgns/src/adfh/ADFH.c:2002:23: error: incompatible function pointer types passing 'herr_t (hid_t, const char *, const H5L_info1_t *, void *)' (aka 'int (long, const char *, const H5L_info1_t *, void *)') to parameter of type 'H5L_iterate2_t' (aka 'int (*)(long, const char *,const H5L_info2_t *, void *)') [-Wincompatible-function-pointer-types]
  - py-cinemasci
  - sz
  - unifyfs
  - veloc
  # - visit               # silo: https://github.com/spack/spack/issues/39538
  - vtk-m ~openmp         # https://github.com/spack/spack/issues/31830
  - zfp
  # --
  # - alquimia                                                # pflotran: https://github.com/spack/spack/issues/39474
  # - dealii                                                  # dealii: https://github.com/spack/spack/issues/39482
  # - dxt-explorer                                            # r: https://github.com/spack/spack/issues/40257
  # - ecp-data-vis-sdk ~cuda ~rocm +adios2 +ascent +cinema +darshan +faodel +hdf5 +paraview +pnetcdf +sz +unifyfs +veloc +visit +vtkm +zfp # embree: CMake Error at CMakeLists.txt:215 (MESSAGE): Unsupported compiler: IntelLLVM; qt: qtbase/src/corelib/global/qendian.h:333:54: error: incomplete type 'std::numeric_limits' used in nested name specifier
  # - geopm                                                   # geopm issue: https://github.com/spack/spack/issues/38795
  # - hpctoolkit                                              # dyninst@12.3.0%gcc: /usr/bin/ld: libiberty/./d-demangle.c:142: undefined reference to `_intel_fast_memcpy'; can't mix intel-tbb@%oneapi with dyninst%gcc
  # - mgard +serial +openmp +timing +unstructured ~cuda       # mgard: mgard.tpp:63:48: error: non-constant-expression cannot be narrowed from type 'int' to 'unsigned long' in initializer list [-Wc++11-narrowing]
  # - openfoam                                                # cgal: https://github.com/spack/spack/issues/39481
  # - openpmd-api                                             # mgard:  mgard.tpp:63:48: error: non-constant-expression cannot be narrowed from type 'int' to 'unsigned long' in initializer list [-Wc++11-narrowing]
  # - swig@4.0.2-fortran                                      # ?
  # - upcxx                                                   # upcxx: /opt/intel/oneapi/mpi/2021.10.0//libfabric/bin/fi_info: error while loading shared libraries: libfabric.so.1: cannot open shared object file: No such file or directory
  # --
  # - bricks ~cuda                                            # bricks: /opt/intel/oneapi/compiler/2024.0/bin/sycl-post-link: error while loading shared libraries: libonnxruntime.1.12.22.721.so: cannot open shared object file: No such file or directory
  # - pdt                                                     # pdt: pdbType.cc:193:21: warning: ISO C++11 does not allow conversion from string literal to 'char *' [-Wwritable-strings]
  # - quantum-espresso                                        # quantum-espresso@7.2 /i3fqdx5: warning: <unknown>:0:0: loop not unroll-and-jammed: the optimizer was unable to perform the requested transformation; the transformation might be disabled or specified as part of an unsupported transformation ordering
  # - tau +mpi +python +syscall                               # pdt: pdbType.cc:193:21: warning: ISO C++11 does not allow conversion from string literal to 'char *' [-Wwritable-strings]

  # PYTHON PACKAGES
  - opencv +python3
  - py-jupyterlab
  - py-notebook
  - py-numpy
  - py-openai
  - py-pandas
  - py-plotly
  - py-pooch
  - py-pytest
  - py-scikit-learn
  - py-scipy
  - py-seaborn
  - py-mpi4py
  - py-numba
  # - py-horovod      # error
  # - py-jax          # error
  # - py-matplotlib   # error
  # - py-tensorflow   # error
  # - py-torch        # error

  # GPU
  - amrex +sycl
  - tau +mpi +opencl +level_zero ~pdt +syscall                # requires libdrm.so to be installed
  - upcxx +level_zero
  # --
  # - hpctoolkit +level_zero            # dyninst@12.3.0%gcc: /usr/bin/ld: libiberty/./d-demangle.c:142: undefined reference to `_intel_fast_memcpy'; can't mix intel-tbb@%oneapi with dyninst%gcc
  # - warpx compute=sycl                # warpx: spack-build-wzp6vvo/_deps/fetchedamrex-src/Src/Base/AMReX_RandomEngine.H:18:10: fatal error: 'oneapi/mkl/rng/device.hpp' file not found
  # --
  - aml                                                     # aml: /opt/intel/oneapi/compiler/2024.0/bin/sycl-post-link: error while loading shared libraries: libonnxruntime.1.12.22.721.so: cannot open shared object file: No such file or directory
  - aml +ze                                                 # aml: /opt/intel/oneapi/compiler/2024.0/bin/sycl-post-link: error while loading shared libraries: libonnxruntime.1.12.22.721.so: cannot open shared object file: No such file or directory
  - arborx +sycl ^kokkos +sycl +openmp cxxstd=17 +examples  # kokkos@4.2.00: CMake Error at cmake/Modules/FindTPLONEDPL.cmake:31 (FIND_PACKAGE):
  - cabana +sycl ^kokkos +sycl +openmp cxxstd=17 +examples  # kokkos@4.2.00: CMake Error at cmake/Modules/FindTPLONEDPL.cmake:31 (FIND_PACKAGE):
  - ginkgo +sycl                                            # ginkgo: Could NOT find PAPI (missing: PAPI_LIBRARY PAPI_INCLUDE_DIR sde) (Required is at least version "7.0.1.0") SYCL feature test compile failed! compile output is: CMake Error at /opt/intel/oneapi/compiler/2024.0/lib/cmake/IntelSYCL/IntelSYCLConfig.cmake:282 (SYCL_FEATURE_TEST_EXTRACT): SYCL_FEATURE_TEST_EXTRACT Function invoked with incorrect arguments for
  - heffte +sycl                                            # heffte: /opt/intel/oneapi/compiler/2024.0/bin/sycl-post-link: error while loading shared libraries: libonnxruntime.1.12.22.721.so: cannot open shared object file: No such file or directory
  - kokkos +sycl +openmp cxxstd=17 +examples                # kokkos@4.2.00: CMake Error at cmake/Modules/FindTPLONEDPL.cmake:31 (FIND_PACKAGE):
  - kokkos-kernels build_type=Release %oneapi ^kokkos +sycl +openmp cxxstd=17 +examples # kokkos@4.0.00: tpls/desul/include/desul/atomics/Adapt_SYCL.hpp:83:7: error: no template named 'sycl_memory_scope'
  - petsc +sycl                                             # kokkos@4.0.00: tpls/desul/include/desul/atomics/Adapt_SYCL.hpp:83:7: error: no template named 'sycl_memory_scope'
  # - slate +sycl                                             # blaspp: CMake Error at CMakeLists.txt:313 (find_package): ... set MKL_FOUND to FALSE so package "MKL" is considered to be NOT FOUND.
  - sundials +sycl cxxstd=17 +examples-install              # sundials@6.6.2 /cakfnxs: CMake: could NOT find MPI_CXX (missing: MPI_CXX_WORKS) (Required is at least version "2.0.0")    

  - py-scipy

  ci:
    pipeline-gen:
    - build-job:
        image: ghcr.io/spack/ubuntu22.04-runner-amd64-oneapi-2024.0.0:2024.01.16b

  cdash:
    build-group: E4S OneAPI
